{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pygame 1.9.5\n",
      "Hello from the pygame community. https://www.pygame.org/contribute.html\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pygame\n",
    "DISPLAY = True\n",
    "if not DISPLAY:\n",
    "    os.environ[\"SDL_VIDEODRIVER\"] = \"dummy\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Double Dueling Deep Q Network Learning with Priortized Experienced Reply"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os,sys\n",
    "sys.path.append('game/')\n",
    "import flappy_wrapped as game\n",
    "import cv2\n",
    "import numpy as np\n",
    "import time\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "KERNEL = np.array([[-1,-1,-1], [-1, 9,-1],[-1,-1,-1]])\n",
    "def processFrame(frame):\n",
    "    frame = frame[55:288,0:400] #crop image\n",
    "    frame = cv2.cvtColor(frame,cv2.COLOR_BGR2GRAY) #convert image to black and white\n",
    "    frame = cv2.resize(frame,(84,84),interpolation=cv2.INTER_AREA)\n",
    "    _ , frame = cv2.threshold(frame,50,255,cv2.THRESH_BINARY)\n",
    "    #frame = cv2.blur(frame,(5,5))\n",
    "    frame = cv2.filter2D(frame,-1,KERNEL)\n",
    "    #frame = cv2.Canny(frame,100,200)\n",
    "    frame = frame.astype(np.float64)/255.0\n",
    "    return frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "#Dueling DQN\n",
    "class DDQN(nn.Module):\n",
    "    def __init__(self,input_shape,nactions):\n",
    "        super(DDQN,self).__init__()\n",
    "        self.nactions = nactions\n",
    "        self.conv = nn.Sequential(\n",
    "            nn.Conv2d(input_shape[0],32,kernel_size=4,stride=2),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(32,64,kernel_size=3,stride=2),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(64,64,kernel_size=2,stride=1),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        \n",
    "        conv_out_size = self._get_conv_out(input_shape)\n",
    "        \n",
    "        self.fca = nn.Sequential(\n",
    "            nn.Linear( conv_out_size, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear( 512, nactions )\n",
    "        )\n",
    "        \n",
    "        self.fcv = nn.Sequential(\n",
    "            nn.Linear(conv_out_size,512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512,1)\n",
    "        )\n",
    "        \n",
    "    def _get_conv_out(self,shape):\n",
    "        o = self.conv( torch.zeros(1,*shape) )\n",
    "        return int(np.prod(o.size()))\n",
    "    \n",
    "    def forward(self,x):\n",
    "        conv_out = self.conv(x).view(x.size()[0], -1)\n",
    "        action_v = self.fca(conv_out)\n",
    "        value_v = self.fcv(conv_out).expand(x.size(0), self.nactions)\n",
    "        return value_v + action_v - action_v.mean(1).unsqueeze(1).expand(x.size(0), self.nactions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ACTIONS = [0,1]\n",
    "EXPERIENCE_BUFFER_SIZE = 2000\n",
    "STATE_DIM = 4\n",
    "GAMMA = 0.99\n",
    "EPSILON_START = 1\n",
    "EPSILON_FINAL = 0.001\n",
    "EPSILON_DECAY_FRAMES = (10**4)/3\n",
    "MEAN_GOAL_REWARD = 10\n",
    "BATCH_SIZE = 32\n",
    "MIN_EXP_BUFFER_SIZE = 500\n",
    "SYNC_TARGET_FRAMES = 30\n",
    "LEARNING_RATE = 1e-4\n",
    "SKIP_FRAME = 2\n",
    "INITIAL_SKIP = [0,1,0,1,0,1,0,0,0,1,0,1,0,1,0,1,0,0,0,0,0,0,0,1,0,1,0,1,0,1,0,1,0,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import collections\n",
    "class ExperienceBuffer():\n",
    "    def __init__(self,capacity):\n",
    "        self.buffer = collections.deque(maxlen=capacity)\n",
    "        self.priority = collections.deque(maxlen=capacity)\n",
    "    \n",
    "    def clear(self):\n",
    "        self.buffer.clear()\n",
    "        self.priority.clear()\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.buffer)\n",
    "    \n",
    "    def append(self,exp,p):\n",
    "        self.buffer.append(exp)\n",
    "        self.priority.append(p)\n",
    "        \n",
    "    def sample(self,batch_size):\n",
    "        probs = np.array(self.priority)/sum(np.array(self.priority))\n",
    "        indices = np.random.choice( range(len(self.buffer)), batch_size, p = probs)\n",
    "        states,actions,rewards,dones,next_states = zip(*[ self.buffer[idx] for idx in indices ])\n",
    "        return np.array(states), np.array(actions), np.array(rewards, dtype=np.float32),\\\n",
    "    np.array(dones,dtype=np.uint8), np.array(next_states)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Agent():\n",
    "    def __init__(self,env,buffer,state_buffer_size = STATE_DIM):\n",
    "        self.env = env\n",
    "        self.exp_buffer = buffer\n",
    "        self.state = collections.deque(maxlen = STATE_DIM)\n",
    "        self.next_state= collections.deque(maxlen = STATE_DIM)\n",
    "        self._reset()\n",
    "        \n",
    "    def _reset(self):\n",
    "        self.total_rewards = 0\n",
    "        self.state.clear()\n",
    "        self.next_state.clear()\n",
    "        \n",
    "        for i in INITIAL_SKIP[:-7]:\n",
    "            frame,reward,done = self.env.frame_step(i)\n",
    "            self.total_rewards+=reward\n",
    "            if done:\n",
    "                self._reset()\n",
    "        frame = processFrame(frame)\n",
    "        self.state.append(frame)\n",
    "        self.next_state.append(frame)\n",
    "\n",
    "        for i in INITIAL_SKIP[-7:-5]:\n",
    "            frame,reward,done = self.env.frame_step(i)\n",
    "            self.total_rewards+=reward\n",
    "            if done:\n",
    "                self._reset()\n",
    "        frame = processFrame(frame)\n",
    "        self.state.append(frame)\n",
    "        self.next_state.append(frame)\n",
    "        \n",
    "        for i in INITIAL_SKIP[-5:-3]:\n",
    "            frame,reward,done = self.env.frame_step(i)\n",
    "            self.total_rewards+=reward\n",
    "            if done:\n",
    "                self._reset()\n",
    "        frame = processFrame(frame)\n",
    "        self.state.append(frame)\n",
    "        self.next_state.append(frame)\n",
    "        \n",
    "        for i in INITIAL_SKIP[-3:-1]:\n",
    "            frame,reward,done = self.env.frame_step(i)\n",
    "            self.total_rewards+=reward\n",
    "            if done:\n",
    "                self._reset()\n",
    "        frame = processFrame(frame)\n",
    "        self.state.append(frame)\n",
    "        self.next_state.append(frame)\n",
    "    \n",
    "    def step(self,net,tgt_net,epsilon=0.9,device='cpu'):\n",
    "        self.total_rewards = 0\n",
    "        if np.random.random() < epsilon:\n",
    "            action = np.random.choice(ACTIONS)\n",
    "        else:\n",
    "            state_v = torch.tensor(np.array([self.state],copy=False),dtype=torch.float32).to(device)\n",
    "            action = int(torch.argmax(net(state_v)))\n",
    "       \n",
    "        frame,reward,done = self.env.frame_step(action)\n",
    "        self.total_rewards += reward\n",
    "        for _ in range(SKIP_FRAME):\n",
    "                frame,reward,done =  self.env.frame_step(action)\n",
    "                self.total_rewards += reward\n",
    "                if done:\n",
    "                    break\n",
    "                    \n",
    "        frame = processFrame(frame)\n",
    "        self.next_state.append(frame)\n",
    "        \n",
    "        if len(self.next_state)==STATE_DIM and len(self.state)==STATE_DIM:\n",
    "            #PER - Prioritized Experience Replay\n",
    "            o = net( torch.tensor( np.array([self.state]),dtype=torch.float32).to(device)).to('cpu').detach().numpy()[0][action]\n",
    "            e = float(torch.max(tgt_net( torch.tensor( np.array([self.next_state]),dtype=torch.float32).to(device))))\n",
    "            p = abs(o-e)+0.0001\n",
    "            self.exp_buffer.append((self.state.copy(),action,int(self.total_rewards),done,self.next_state.copy()),p)\n",
    "        \n",
    "        self.state.append(frame)\n",
    "        \n",
    "        end_reward = int(self.total_rewards)\n",
    "        if done:\n",
    "            self._reset()\n",
    "        \n",
    "        return end_reward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def calc_loss(batch,net,tgt_net,device='cpu'):\n",
    "    states,actions,rewards,dones,next_states = batch\n",
    "    \n",
    "    states_v = torch.tensor(states,dtype=torch.float32).to(device)\n",
    "    actions_v = torch.tensor(actions,dtype=torch.long).to(device)\n",
    "    rewards_v = torch.tensor(rewards).to(device)\n",
    "    dones_v = torch.ByteTensor(dones).to(device)\n",
    "    next_states_v = torch.tensor(next_states,dtype=torch.float32).to(device)\n",
    "    \n",
    "    state_action_values = net(states_v).gather(1, actions_v.unsqueeze(-1)).squeeze(-1)\n",
    "    next_state_action_values = tgt_net(next_states_v).max(1)[0]\n",
    "    next_state_action_values[dones_v] = 0.0\n",
    "    next_state_action_values = next_state_action_values.detach() \n",
    "    \n",
    "    expected_values = rewards_v +  next_state_action_values * GAMMA\n",
    "    return nn.MSELoss()(state_action_values,expected_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "REWARD -inf -> -1.0. Model Saved\n",
      "GAME : 5 | EPSILON : 0.9988 | MEAN REWARD : -1.0\n",
      "REWARD -1.0 -> -0.6666666666666666. Model Saved\n",
      "GAME : 10 | EPSILON : 0.9973 | MEAN REWARD : -0.8\n",
      "GAME : 15 | EPSILON : 0.9958 | MEAN REWARD : -0.6\n",
      "GAME : 20 | EPSILON : 0.9943 | MEAN REWARD : -0.6\n",
      "REWARD -0.6666666666666666 -> -0.5454545454545454. Model Saved\n",
      "GAME : 25 | EPSILON : 0.9928 | MEAN REWARD : -0.6\n",
      "GAME : 30 | EPSILON : 0.9913 | MEAN REWARD : -0.6666666666666666\n",
      "GAME : 35 | EPSILON : 0.9898 | MEAN REWARD : -0.6571428571428571\n",
      "GAME : 40 | EPSILON : 0.9883 | MEAN REWARD : -0.7\n",
      "GAME : 45 | EPSILON : 0.9868 | MEAN REWARD : -0.7333333333333333\n",
      "GAME : 50 | EPSILON : 0.9853 | MEAN REWARD : -0.76\n",
      "GAME : 55 | EPSILON : 0.9838 | MEAN REWARD : -0.7454545454545455\n",
      "GAME : 60 | EPSILON : 0.9823 | MEAN REWARD : -0.7666666666666667\n",
      "GAME : 65 | EPSILON : 0.9808 | MEAN REWARD : -0.7846153846153846\n",
      "GAME : 70 | EPSILON : 0.9793 | MEAN REWARD : -0.8\n",
      "GAME : 75 | EPSILON : 0.9778 | MEAN REWARD : -0.7866666666666666\n",
      "GAME : 80 | EPSILON : 0.9763 | MEAN REWARD : -0.775\n",
      "GAME : 85 | EPSILON : 0.9748 | MEAN REWARD : -0.788235294117647\n",
      "GAME : 90 | EPSILON : 0.9733 | MEAN REWARD : -0.8\n",
      "GAME : 95 | EPSILON : 0.9718 | MEAN REWARD : -0.8105263157894737\n",
      "GAME : 100 | EPSILON : 0.9703 | MEAN REWARD : -0.82\n",
      "GAME : 105 | EPSILON : 0.9688 | MEAN REWARD : -0.8\n",
      "GAME : 110 | EPSILON : 0.9673 | MEAN REWARD : -0.82\n",
      "GAME : 115 | EPSILON : 0.9658 | MEAN REWARD : -0.86\n",
      "GAME : 120 | EPSILON : 0.9643 | MEAN REWARD : -0.88\n",
      "GAME : 125 | EPSILON : 0.9628 | MEAN REWARD : -0.9\n",
      "GAME : 130 | EPSILON : 0.9613 | MEAN REWARD : -0.88\n",
      "GAME : 135 | EPSILON : 0.9598 | MEAN REWARD : -0.9\n",
      "GAME : 140 | EPSILON : 0.9583 | MEAN REWARD : -0.9\n",
      "GAME : 145 | EPSILON : 0.9568 | MEAN REWARD : -0.9\n",
      "GAME : 150 | EPSILON : 0.9553 | MEAN REWARD : -0.9\n",
      "GAME : 155 | EPSILON : 0.9538 | MEAN REWARD : -0.92\n",
      "GAME : 160 | EPSILON : 0.9523 | MEAN REWARD : -0.92\n",
      "GAME : 165 | EPSILON : 0.9508 | MEAN REWARD : -0.92\n",
      "GAME : 170 | EPSILON : 0.9493 | MEAN REWARD : -0.92\n",
      "GAME : 175 | EPSILON : 0.9478 | MEAN REWARD : -0.94\n",
      "GAME : 180 | EPSILON : 0.9463 | MEAN REWARD : -0.96\n",
      "GAME : 185 | EPSILON : 0.9448 | MEAN REWARD : -0.96\n",
      "GAME : 190 | EPSILON : 0.9433 | MEAN REWARD : -0.96\n",
      "GAME : 195 | EPSILON : 0.9418 | MEAN REWARD : -0.96\n",
      "GAME : 200 | EPSILON : 0.9403 | MEAN REWARD : -0.96\n",
      "GAME : 205 | EPSILON : 0.9388 | MEAN REWARD : -0.96\n",
      "GAME : 210 | EPSILON : 0.9373 | MEAN REWARD : -0.96\n",
      "GAME : 215 | EPSILON : 0.9358 | MEAN REWARD : -0.96\n",
      "GAME : 220 | EPSILON : 0.9343 | MEAN REWARD : -0.96\n",
      "GAME : 225 | EPSILON : 0.9328 | MEAN REWARD : -0.96\n",
      "GAME : 230 | EPSILON : 0.9313 | MEAN REWARD : -0.98\n",
      "GAME : 235 | EPSILON : 0.9298 | MEAN REWARD : -0.98\n",
      "GAME : 240 | EPSILON : 0.9283 | MEAN REWARD : -0.96\n",
      "GAME : 245 | EPSILON : 0.9268 | MEAN REWARD : -0.96\n",
      "GAME : 250 | EPSILON : 0.9253 | MEAN REWARD : -0.96\n",
      "GAME : 255 | EPSILON : 0.9238 | MEAN REWARD : -0.94\n",
      "GAME : 260 | EPSILON : 0.9223 | MEAN REWARD : -0.92\n",
      "GAME : 265 | EPSILON : 0.9208 | MEAN REWARD : -0.92\n",
      "GAME : 270 | EPSILON : 0.9193 | MEAN REWARD : -0.9\n",
      "GAME : 275 | EPSILON : 0.9178 | MEAN REWARD : -0.9\n",
      "GAME : 280 | EPSILON : 0.9163 | MEAN REWARD : -0.9\n",
      "GAME : 285 | EPSILON : 0.9148 | MEAN REWARD : -0.9\n",
      "GAME : 290 | EPSILON : 0.9133 | MEAN REWARD : -0.9\n",
      "GAME : 295 | EPSILON : 0.9118 | MEAN REWARD : -0.9\n",
      "GAME : 300 | EPSILON : 0.9103 | MEAN REWARD : -0.88\n",
      "GAME : 305 | EPSILON : 0.9088 | MEAN REWARD : -0.9\n",
      "GAME : 310 | EPSILON : 0.9073 | MEAN REWARD : -0.9\n",
      "GAME : 315 | EPSILON : 0.9058 | MEAN REWARD : -0.9\n",
      "GAME : 320 | EPSILON : 0.9043 | MEAN REWARD : -0.9\n",
      "GAME : 325 | EPSILON : 0.9028 | MEAN REWARD : -0.88\n",
      "GAME : 330 | EPSILON : 0.9013 | MEAN REWARD : -0.88\n",
      "GAME : 335 | EPSILON : 0.8998 | MEAN REWARD : -0.88\n",
      "GAME : 340 | EPSILON : 0.8983 | MEAN REWARD : -0.9\n",
      "GAME : 345 | EPSILON : 0.8968 | MEAN REWARD : -0.9\n",
      "GAME : 350 | EPSILON : 0.8953 | MEAN REWARD : -0.9\n",
      "GAME : 355 | EPSILON : 0.8938 | MEAN REWARD : -0.92\n",
      "GAME : 360 | EPSILON : 0.8923 | MEAN REWARD : -0.94\n",
      "GAME : 365 | EPSILON : 0.8908 | MEAN REWARD : -0.94\n",
      "GAME : 370 | EPSILON : 0.8893 | MEAN REWARD : -0.96\n",
      "GAME : 375 | EPSILON : 0.8878 | MEAN REWARD : -0.94\n",
      "GAME : 380 | EPSILON : 0.8863 | MEAN REWARD : -0.94\n",
      "GAME : 385 | EPSILON : 0.8848 | MEAN REWARD : -0.92\n",
      "GAME : 390 | EPSILON : 0.8833 | MEAN REWARD : -0.92\n",
      "GAME : 395 | EPSILON : 0.8818 | MEAN REWARD : -0.9\n",
      "GAME : 400 | EPSILON : 0.8803 | MEAN REWARD : -0.9\n",
      "GAME : 405 | EPSILON : 0.8788 | MEAN REWARD : -0.88\n",
      "GAME : 410 | EPSILON : 0.8773 | MEAN REWARD : -0.88\n",
      "GAME : 415 | EPSILON : 0.8758 | MEAN REWARD : -0.88\n",
      "GAME : 420 | EPSILON : 0.8743 | MEAN REWARD : -0.86\n",
      "GAME : 425 | EPSILON : 0.8728 | MEAN REWARD : -0.88\n",
      "GAME : 430 | EPSILON : 0.8713 | MEAN REWARD : -0.88\n",
      "GAME : 435 | EPSILON : 0.8698 | MEAN REWARD : -0.88\n",
      "GAME : 440 | EPSILON : 0.8683 | MEAN REWARD : -0.86\n",
      "GAME : 445 | EPSILON : 0.8668 | MEAN REWARD : -0.84\n",
      "GAME : 450 | EPSILON : 0.8653 | MEAN REWARD : -0.84\n",
      "GAME : 455 | EPSILON : 0.8638 | MEAN REWARD : -0.84\n",
      "GAME : 460 | EPSILON : 0.8623 | MEAN REWARD : -0.82\n",
      "GAME : 465 | EPSILON : 0.8608 | MEAN REWARD : -0.8\n",
      "GAME : 470 | EPSILON : 0.8593 | MEAN REWARD : -0.8\n",
      "GAME : 475 | EPSILON : 0.8578 | MEAN REWARD : -0.82\n",
      "GAME : 480 | EPSILON : 0.8563 | MEAN REWARD : -0.8\n",
      "GAME : 485 | EPSILON : 0.8548 | MEAN REWARD : -0.82\n",
      "GAME : 490 | EPSILON : 0.8533 | MEAN REWARD : -0.8\n",
      "GAME : 495 | EPSILON : 0.8518 | MEAN REWARD : -0.82\n",
      "GAME : 500 | EPSILON : 0.8503 | MEAN REWARD : -0.82\n",
      "GAME : 505 | EPSILON : 0.8488 | MEAN REWARD : -0.82\n",
      "GAME : 510 | EPSILON : 0.8473 | MEAN REWARD : -0.82\n",
      "GAME : 515 | EPSILON : 0.8458 | MEAN REWARD : -0.8\n",
      "GAME : 520 | EPSILON : 0.8443 | MEAN REWARD : -0.82\n",
      "GAME : 525 | EPSILON : 0.8428 | MEAN REWARD : -0.82\n",
      "GAME : 530 | EPSILON : 0.8413 | MEAN REWARD : -0.8\n",
      "GAME : 535 | EPSILON : 0.8398 | MEAN REWARD : -0.78\n",
      "GAME : 540 | EPSILON : 0.8383 | MEAN REWARD : -0.8\n",
      "GAME : 545 | EPSILON : 0.8368 | MEAN REWARD : -0.8\n",
      "GAME : 550 | EPSILON : 0.8353 | MEAN REWARD : -0.8\n",
      "GAME : 555 | EPSILON : 0.8338 | MEAN REWARD : -0.78\n",
      "GAME : 560 | EPSILON : 0.8323 | MEAN REWARD : -0.78\n",
      "GAME : 565 | EPSILON : 0.8308 | MEAN REWARD : -0.8\n",
      "GAME : 570 | EPSILON : 0.8293 | MEAN REWARD : -0.8\n",
      "GAME : 575 | EPSILON : 0.8278 | MEAN REWARD : -0.78\n",
      "GAME : 580 | EPSILON : 0.8263 | MEAN REWARD : -0.78\n",
      "GAME : 585 | EPSILON : 0.8248 | MEAN REWARD : -0.78\n",
      "GAME : 590 | EPSILON : 0.8233 | MEAN REWARD : -0.8\n",
      "GAME : 595 | EPSILON : 0.8218 | MEAN REWARD : -0.78\n",
      "GAME : 600 | EPSILON : 0.8203 | MEAN REWARD : -0.8\n",
      "GAME : 605 | EPSILON : 0.8188 | MEAN REWARD : -0.82\n",
      "GAME : 610 | EPSILON : 0.8173 | MEAN REWARD : -0.82\n",
      "GAME : 615 | EPSILON : 0.8158 | MEAN REWARD : -0.8\n",
      "GAME : 620 | EPSILON : 0.8143 | MEAN REWARD : -0.78\n",
      "GAME : 625 | EPSILON : 0.8128 | MEAN REWARD : -0.78\n",
      "GAME : 630 | EPSILON : 0.8113 | MEAN REWARD : -0.78\n",
      "GAME : 635 | EPSILON : 0.8098 | MEAN REWARD : -0.8\n",
      "GAME : 640 | EPSILON : 0.8083 | MEAN REWARD : -0.78\n",
      "GAME : 645 | EPSILON : 0.8068 | MEAN REWARD : -0.8\n",
      "GAME : 650 | EPSILON : 0.8053 | MEAN REWARD : -0.8\n",
      "GAME : 655 | EPSILON : 0.8038 | MEAN REWARD : -0.82\n",
      "GAME : 660 | EPSILON : 0.8023 | MEAN REWARD : -0.84\n",
      "GAME : 665 | EPSILON : 0.8008 | MEAN REWARD : -0.82\n",
      "GAME : 670 | EPSILON : 0.7993 | MEAN REWARD : -0.82\n",
      "GAME : 675 | EPSILON : 0.7978 | MEAN REWARD : -0.8\n",
      "GAME : 680 | EPSILON : 0.7963 | MEAN REWARD : -0.78\n",
      "GAME : 685 | EPSILON : 0.7948 | MEAN REWARD : -0.78\n",
      "GAME : 690 | EPSILON : 0.7933 | MEAN REWARD : -0.76\n",
      "GAME : 695 | EPSILON : 0.7918 | MEAN REWARD : -0.76\n",
      "GAME : 700 | EPSILON : 0.7903 | MEAN REWARD : -0.72\n",
      "GAME : 705 | EPSILON : 0.7888 | MEAN REWARD : -0.72\n",
      "GAME : 710 | EPSILON : 0.7873 | MEAN REWARD : -0.72\n",
      "GAME : 715 | EPSILON : 0.7858 | MEAN REWARD : -0.74\n",
      "GAME : 720 | EPSILON : 0.7843 | MEAN REWARD : -0.72\n",
      "GAME : 725 | EPSILON : 0.7828 | MEAN REWARD : -0.7\n",
      "GAME : 730 | EPSILON : 0.7813 | MEAN REWARD : -0.72\n",
      "GAME : 735 | EPSILON : 0.7798 | MEAN REWARD : -0.72\n",
      "GAME : 740 | EPSILON : 0.7783 | MEAN REWARD : -0.72\n",
      "GAME : 745 | EPSILON : 0.7768 | MEAN REWARD : -0.72\n",
      "GAME : 750 | EPSILON : 0.7753 | MEAN REWARD : -0.72\n",
      "GAME : 755 | EPSILON : 0.7738 | MEAN REWARD : -0.68\n",
      "GAME : 760 | EPSILON : 0.7723 | MEAN REWARD : -0.68\n",
      "GAME : 765 | EPSILON : 0.7708 | MEAN REWARD : -0.7\n",
      "GAME : 770 | EPSILON : 0.7693 | MEAN REWARD : -0.7\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GAME : 775 | EPSILON : 0.7678 | MEAN REWARD : -0.74\n",
      "GAME : 780 | EPSILON : 0.7663 | MEAN REWARD : -0.78\n",
      "GAME : 785 | EPSILON : 0.7648 | MEAN REWARD : -0.76\n",
      "GAME : 790 | EPSILON : 0.7633 | MEAN REWARD : -0.78\n",
      "GAME : 795 | EPSILON : 0.7618 | MEAN REWARD : -0.8\n",
      "GAME : 800 | EPSILON : 0.7603 | MEAN REWARD : -0.84\n",
      "GAME : 805 | EPSILON : 0.7588 | MEAN REWARD : -0.82\n",
      "GAME : 810 | EPSILON : 0.7573 | MEAN REWARD : -0.8\n",
      "GAME : 815 | EPSILON : 0.7558 | MEAN REWARD : -0.8\n",
      "GAME : 820 | EPSILON : 0.7543 | MEAN REWARD : -0.82\n",
      "GAME : 825 | EPSILON : 0.7528 | MEAN REWARD : -0.8\n",
      "GAME : 830 | EPSILON : 0.7513 | MEAN REWARD : -0.78\n",
      "GAME : 835 | EPSILON : 0.7498 | MEAN REWARD : -0.76\n",
      "GAME : 840 | EPSILON : 0.7483 | MEAN REWARD : -0.78\n",
      "GAME : 845 | EPSILON : 0.7468 | MEAN REWARD : -0.78\n",
      "GAME : 850 | EPSILON : 0.7453 | MEAN REWARD : -0.78\n",
      "GAME : 855 | EPSILON : 0.7438 | MEAN REWARD : -0.82\n",
      "GAME : 860 | EPSILON : 0.7423 | MEAN REWARD : -0.82\n",
      "GAME : 865 | EPSILON : 0.7408 | MEAN REWARD : -0.8\n",
      "GAME : 870 | EPSILON : 0.7393 | MEAN REWARD : -0.78\n",
      "GAME : 875 | EPSILON : 0.7378 | MEAN REWARD : -0.78\n",
      "GAME : 880 | EPSILON : 0.7363 | MEAN REWARD : -0.78\n",
      "GAME : 885 | EPSILON : 0.7348 | MEAN REWARD : -0.78\n",
      "GAME : 890 | EPSILON : 0.7333 | MEAN REWARD : -0.74\n",
      "GAME : 895 | EPSILON : 0.7318 | MEAN REWARD : -0.72\n",
      "GAME : 900 | EPSILON : 0.7303 | MEAN REWARD : -0.7\n",
      "GAME : 905 | EPSILON : 0.7288 | MEAN REWARD : -0.7\n",
      "GAME : 910 | EPSILON : 0.7273 | MEAN REWARD : -0.7\n",
      "GAME : 915 | EPSILON : 0.7258 | MEAN REWARD : -0.72\n",
      "GAME : 920 | EPSILON : 0.7243 | MEAN REWARD : -0.72\n",
      "GAME : 925 | EPSILON : 0.7228 | MEAN REWARD : -0.76\n",
      "GAME : 930 | EPSILON : 0.7213 | MEAN REWARD : -0.76\n",
      "GAME : 935 | EPSILON : 0.7198 | MEAN REWARD : -0.76\n",
      "GAME : 940 | EPSILON : 0.7183 | MEAN REWARD : -0.72\n",
      "GAME : 945 | EPSILON : 0.7168 | MEAN REWARD : -0.7\n",
      "GAME : 950 | EPSILON : 0.7153 | MEAN REWARD : -0.7\n",
      "GAME : 955 | EPSILON : 0.7138 | MEAN REWARD : -0.7\n",
      "GAME : 960 | EPSILON : 0.7123 | MEAN REWARD : -0.68\n",
      "GAME : 965 | EPSILON : 0.7108 | MEAN REWARD : -0.68\n",
      "GAME : 970 | EPSILON : 0.7093 | MEAN REWARD : -0.68\n",
      "GAME : 975 | EPSILON : 0.7078 | MEAN REWARD : -0.66\n",
      "GAME : 980 | EPSILON : 0.7063 | MEAN REWARD : -0.66\n",
      "GAME : 985 | EPSILON : 0.7048 | MEAN REWARD : -0.66\n",
      "GAME : 990 | EPSILON : 0.7033 | MEAN REWARD : -0.66\n",
      "GAME : 995 | EPSILON : 0.7018 | MEAN REWARD : -0.64\n",
      "GAME : 1000 | EPSILON : 0.7003 | MEAN REWARD : -0.66\n",
      "GAME : 1005 | EPSILON : 0.6988 | MEAN REWARD : -0.68\n",
      "GAME : 1010 | EPSILON : 0.6973 | MEAN REWARD : -0.68\n",
      "GAME : 1015 | EPSILON : 0.6958 | MEAN REWARD : -0.68\n",
      "GAME : 1020 | EPSILON : 0.6943 | MEAN REWARD : -0.68\n",
      "GAME : 1025 | EPSILON : 0.6928 | MEAN REWARD : -0.66\n",
      "GAME : 1030 | EPSILON : 0.6913 | MEAN REWARD : -0.68\n",
      "GAME : 1035 | EPSILON : 0.6898 | MEAN REWARD : -0.68\n",
      "GAME : 1040 | EPSILON : 0.6883 | MEAN REWARD : -0.72\n",
      "GAME : 1045 | EPSILON : 0.6868 | MEAN REWARD : -0.74\n",
      "GAME : 1050 | EPSILON : 0.6853 | MEAN REWARD : -0.74\n",
      "GAME : 1055 | EPSILON : 0.6838 | MEAN REWARD : -0.68\n",
      "GAME : 1060 | EPSILON : 0.6823 | MEAN REWARD : -0.68\n",
      "GAME : 1065 | EPSILON : 0.6808 | MEAN REWARD : -0.66\n",
      "GAME : 1070 | EPSILON : 0.6793 | MEAN REWARD : -0.66\n",
      "GAME : 1075 | EPSILON : 0.6778 | MEAN REWARD : -0.66\n",
      "GAME : 1080 | EPSILON : 0.6763 | MEAN REWARD : -0.64\n",
      "GAME : 1085 | EPSILON : 0.6748 | MEAN REWARD : -0.62\n",
      "GAME : 1090 | EPSILON : 0.6733 | MEAN REWARD : -0.62\n",
      "GAME : 1095 | EPSILON : 0.6718 | MEAN REWARD : -0.62\n",
      "GAME : 1100 | EPSILON : 0.6703 | MEAN REWARD : -0.6\n",
      "GAME : 1105 | EPSILON : 0.6688 | MEAN REWARD : -0.6\n",
      "GAME : 1110 | EPSILON : 0.6673 | MEAN REWARD : -0.62\n",
      "GAME : 1115 | EPSILON : 0.6658 | MEAN REWARD : -0.58\n",
      "GAME : 1120 | EPSILON : 0.6643 | MEAN REWARD : -0.58\n",
      "GAME : 1125 | EPSILON : 0.6628 | MEAN REWARD : -0.58\n",
      "GAME : 1130 | EPSILON : 0.6613 | MEAN REWARD : -0.56\n",
      "GAME : 1135 | EPSILON : 0.6598 | MEAN REWARD : -0.58\n",
      "GAME : 1140 | EPSILON : 0.6583 | MEAN REWARD : -0.56\n",
      "GAME : 1145 | EPSILON : 0.6568 | MEAN REWARD : -0.56\n",
      "GAME : 1150 | EPSILON : 0.6553 | MEAN REWARD : -0.56\n",
      "GAME : 1155 | EPSILON : 0.6538 | MEAN REWARD : -0.62\n",
      "GAME : 1160 | EPSILON : 0.6523 | MEAN REWARD : -0.62\n",
      "GAME : 1165 | EPSILON : 0.6508 | MEAN REWARD : -0.64\n",
      "GAME : 1170 | EPSILON : 0.6493 | MEAN REWARD : -0.64\n",
      "GAME : 1175 | EPSILON : 0.6478 | MEAN REWARD : -0.64\n",
      "GAME : 1180 | EPSILON : 0.6463 | MEAN REWARD : -0.64\n",
      "GAME : 1185 | EPSILON : 0.6448 | MEAN REWARD : -0.66\n",
      "GAME : 1190 | EPSILON : 0.6433 | MEAN REWARD : -0.7\n",
      "GAME : 1195 | EPSILON : 0.6418 | MEAN REWARD : -0.72\n",
      "GAME : 1200 | EPSILON : 0.6403 | MEAN REWARD : -0.72\n",
      "GAME : 1205 | EPSILON : 0.6388 | MEAN REWARD : -0.7\n",
      "GAME : 1210 | EPSILON : 0.6373 | MEAN REWARD : -0.7\n",
      "GAME : 1215 | EPSILON : 0.6358 | MEAN REWARD : -0.72\n",
      "GAME : 1220 | EPSILON : 0.6343 | MEAN REWARD : -0.74\n",
      "GAME : 1225 | EPSILON : 0.6328 | MEAN REWARD : -0.76\n",
      "GAME : 1230 | EPSILON : 0.6313 | MEAN REWARD : -0.76\n",
      "GAME : 1235 | EPSILON : 0.6298 | MEAN REWARD : -0.76\n",
      "GAME : 1240 | EPSILON : 0.6283 | MEAN REWARD : -0.74\n",
      "GAME : 1245 | EPSILON : 0.6268 | MEAN REWARD : -0.72\n",
      "GAME : 1250 | EPSILON : 0.6253 | MEAN REWARD : -0.7\n",
      "GAME : 1255 | EPSILON : 0.6238 | MEAN REWARD : -0.7\n",
      "GAME : 1260 | EPSILON : 0.6223 | MEAN REWARD : -0.68\n",
      "GAME : 1265 | EPSILON : 0.6208 | MEAN REWARD : -0.68\n",
      "GAME : 1270 | EPSILON : 0.6193 | MEAN REWARD : -0.66\n",
      "GAME : 1275 | EPSILON : 0.6178 | MEAN REWARD : -0.66\n",
      "GAME : 1280 | EPSILON : 0.6163 | MEAN REWARD : -0.64\n",
      "GAME : 1285 | EPSILON : 0.6148 | MEAN REWARD : -0.66\n",
      "GAME : 1290 | EPSILON : 0.6133 | MEAN REWARD : -0.64\n",
      "GAME : 1295 | EPSILON : 0.6118 | MEAN REWARD : -0.66\n",
      "GAME : 1300 | EPSILON : 0.6103 | MEAN REWARD : -0.68\n",
      "GAME : 1305 | EPSILON : 0.6088 | MEAN REWARD : -0.68\n",
      "GAME : 1310 | EPSILON : 0.6073 | MEAN REWARD : -0.66\n",
      "GAME : 1315 | EPSILON : 0.6058 | MEAN REWARD : -0.62\n",
      "GAME : 1320 | EPSILON : 0.6043 | MEAN REWARD : -0.62\n",
      "GAME : 1325 | EPSILON : 0.6028 | MEAN REWARD : -0.56\n",
      "GAME : 1330 | EPSILON : 0.6013 | MEAN REWARD : -0.54\n",
      "GAME : 1335 | EPSILON : 0.5998 | MEAN REWARD : -0.52\n",
      "GAME : 1340 | EPSILON : 0.5983 | MEAN REWARD : -0.54\n",
      "GAME : 1345 | EPSILON : 0.5968 | MEAN REWARD : -0.54\n",
      "GAME : 1350 | EPSILON : 0.5953 | MEAN REWARD : -0.5\n",
      "REWARD -0.5454545454545454 -> -0.44. Model Saved\n",
      "GAME : 1355 | EPSILON : 0.5938 | MEAN REWARD : -0.44\n",
      "GAME : 1360 | EPSILON : 0.5923 | MEAN REWARD : -0.46\n",
      "GAME : 1365 | EPSILON : 0.5908 | MEAN REWARD : -0.48\n",
      "GAME : 1370 | EPSILON : 0.5893 | MEAN REWARD : -0.5\n",
      "GAME : 1375 | EPSILON : 0.5878 | MEAN REWARD : -0.48\n",
      "GAME : 1380 | EPSILON : 0.5863 | MEAN REWARD : -0.48\n",
      "GAME : 1385 | EPSILON : 0.5848 | MEAN REWARD : -0.48\n",
      "GAME : 1390 | EPSILON : 0.5833 | MEAN REWARD : -0.44\n",
      "GAME : 1395 | EPSILON : 0.5818 | MEAN REWARD : -0.42\n",
      "GAME : 1400 | EPSILON : 0.5803 | MEAN REWARD : -0.42\n",
      "GAME : 1405 | EPSILON : 0.5788 | MEAN REWARD : -0.44\n",
      "GAME : 1410 | EPSILON : 0.5773 | MEAN REWARD : -0.46\n",
      "GAME : 1415 | EPSILON : 0.5758 | MEAN REWARD : -0.5\n",
      "GAME : 1420 | EPSILON : 0.5743 | MEAN REWARD : -0.46\n",
      "GAME : 1425 | EPSILON : 0.5728 | MEAN REWARD : -0.48\n",
      "GAME : 1430 | EPSILON : 0.5713 | MEAN REWARD : -0.48\n",
      "GAME : 1435 | EPSILON : 0.5698 | MEAN REWARD : -0.5\n",
      "GAME : 1440 | EPSILON : 0.5683 | MEAN REWARD : -0.52\n",
      "GAME : 1445 | EPSILON : 0.5668 | MEAN REWARD : -0.54\n",
      "GAME : 1450 | EPSILON : 0.5653 | MEAN REWARD : -0.58\n",
      "GAME : 1455 | EPSILON : 0.5638 | MEAN REWARD : -0.62\n",
      "GAME : 1460 | EPSILON : 0.5623 | MEAN REWARD : -0.6\n",
      "GAME : 1465 | EPSILON : 0.5608 | MEAN REWARD : -0.6\n",
      "GAME : 1470 | EPSILON : 0.5593 | MEAN REWARD : -0.58\n",
      "GAME : 1475 | EPSILON : 0.5578 | MEAN REWARD : -0.6\n",
      "GAME : 1480 | EPSILON : 0.5563 | MEAN REWARD : -0.62\n",
      "GAME : 1485 | EPSILON : 0.5548 | MEAN REWARD : -0.62\n",
      "GAME : 1490 | EPSILON : 0.5533 | MEAN REWARD : -0.64\n",
      "GAME : 1495 | EPSILON : 0.5518 | MEAN REWARD : -0.64\n",
      "GAME : 1500 | EPSILON : 0.5503 | MEAN REWARD : -0.6\n",
      "GAME : 1505 | EPSILON : 0.5488 | MEAN REWARD : -0.54\n",
      "GAME : 1510 | EPSILON : 0.5473 | MEAN REWARD : -0.52\n",
      "GAME : 1515 | EPSILON : 0.5458 | MEAN REWARD : -0.5\n",
      "GAME : 1520 | EPSILON : 0.5443 | MEAN REWARD : -0.54\n",
      "GAME : 1525 | EPSILON : 0.5428 | MEAN REWARD : -0.56\n",
      "GAME : 1530 | EPSILON : 0.5413 | MEAN REWARD : -0.56\n",
      "GAME : 1535 | EPSILON : 0.5398 | MEAN REWARD : -0.5\n",
      "GAME : 1540 | EPSILON : 0.5383 | MEAN REWARD : -0.46\n",
      "GAME : 1545 | EPSILON : 0.5368 | MEAN REWARD : -0.42\n",
      "GAME : 1550 | EPSILON : 0.5353 | MEAN REWARD : -0.38\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GAME : 1555 | EPSILON : 0.5338 | MEAN REWARD : -0.38\n",
      "GAME : 1560 | EPSILON : 0.5323 | MEAN REWARD : -0.42\n",
      "GAME : 1565 | EPSILON : 0.5308 | MEAN REWARD : -0.4\n",
      "GAME : 1570 | EPSILON : 0.5293 | MEAN REWARD : -0.36\n",
      "GAME : 1575 | EPSILON : 0.5278 | MEAN REWARD : -0.34\n",
      "REWARD -0.44 -> -0.32. Model Saved\n",
      "GAME : 1580 | EPSILON : 0.5263 | MEAN REWARD : -0.3\n",
      "GAME : 1585 | EPSILON : 0.5248 | MEAN REWARD : -0.26\n",
      "GAME : 1590 | EPSILON : 0.5233 | MEAN REWARD : -0.3\n",
      "GAME : 1595 | EPSILON : 0.5218 | MEAN REWARD : -0.28\n",
      "GAME : 1600 | EPSILON : 0.5203 | MEAN REWARD : -0.28\n",
      "GAME : 1605 | EPSILON : 0.5188 | MEAN REWARD : -0.3\n",
      "GAME : 1610 | EPSILON : 0.5173 | MEAN REWARD : -0.26\n",
      "GAME : 1615 | EPSILON : 0.5158 | MEAN REWARD : -0.28\n",
      "GAME : 1620 | EPSILON : 0.5143 | MEAN REWARD : -0.24\n",
      "REWARD -0.32 -> -0.22. Model Saved\n",
      "GAME : 1625 | EPSILON : 0.5128 | MEAN REWARD : -0.24\n",
      "GAME : 1630 | EPSILON : 0.5113 | MEAN REWARD : -0.26\n",
      "GAME : 1635 | EPSILON : 0.5098 | MEAN REWARD : -0.3\n",
      "GAME : 1640 | EPSILON : 0.5083 | MEAN REWARD : -0.3\n",
      "GAME : 1645 | EPSILON : 0.5068 | MEAN REWARD : -0.34\n",
      "GAME : 1650 | EPSILON : 0.5053 | MEAN REWARD : -0.36\n",
      "GAME : 1655 | EPSILON : 0.5038 | MEAN REWARD : -0.34\n",
      "GAME : 1660 | EPSILON : 0.5023 | MEAN REWARD : -0.34\n",
      "GAME : 1665 | EPSILON : 0.5008 | MEAN REWARD : -0.34\n",
      "GAME : 1670 | EPSILON : 0.4993 | MEAN REWARD : -0.36\n",
      "GAME : 1675 | EPSILON : 0.4978 | MEAN REWARD : -0.34\n",
      "GAME : 1680 | EPSILON : 0.4963 | MEAN REWARD : -0.38\n",
      "GAME : 1685 | EPSILON : 0.4948 | MEAN REWARD : -0.4\n",
      "GAME : 1690 | EPSILON : 0.4933 | MEAN REWARD : -0.36\n",
      "GAME : 1695 | EPSILON : 0.4918 | MEAN REWARD : -0.38\n",
      "GAME : 1700 | EPSILON : 0.4903 | MEAN REWARD : -0.4\n",
      "GAME : 1705 | EPSILON : 0.4888 | MEAN REWARD : -0.42\n",
      "GAME : 1710 | EPSILON : 0.4873 | MEAN REWARD : -0.42\n",
      "GAME : 1715 | EPSILON : 0.4858 | MEAN REWARD : -0.44\n",
      "GAME : 1720 | EPSILON : 0.4843 | MEAN REWARD : -0.46\n",
      "GAME : 1725 | EPSILON : 0.4828 | MEAN REWARD : -0.46\n",
      "GAME : 1730 | EPSILON : 0.4813 | MEAN REWARD : -0.46\n",
      "GAME : 1735 | EPSILON : 0.4798 | MEAN REWARD : -0.46\n",
      "GAME : 1740 | EPSILON : 0.4783 | MEAN REWARD : -0.44\n",
      "GAME : 1745 | EPSILON : 0.4768 | MEAN REWARD : -0.42\n",
      "GAME : 1750 | EPSILON : 0.4753 | MEAN REWARD : -0.44\n",
      "GAME : 1755 | EPSILON : 0.4738 | MEAN REWARD : -0.44\n",
      "GAME : 1760 | EPSILON : 0.4723 | MEAN REWARD : -0.38\n",
      "GAME : 1765 | EPSILON : 0.4708 | MEAN REWARD : -0.4\n",
      "GAME : 1770 | EPSILON : 0.4693 | MEAN REWARD : -0.44\n",
      "GAME : 1775 | EPSILON : 0.4678 | MEAN REWARD : -0.46\n",
      "GAME : 1780 | EPSILON : 0.4663 | MEAN REWARD : -0.46\n",
      "GAME : 1785 | EPSILON : 0.4648 | MEAN REWARD : -0.44\n",
      "GAME : 1790 | EPSILON : 0.4633 | MEAN REWARD : -0.42\n",
      "GAME : 1795 | EPSILON : 0.4618 | MEAN REWARD : -0.4\n",
      "GAME : 1800 | EPSILON : 0.4603 | MEAN REWARD : -0.4\n",
      "GAME : 1805 | EPSILON : 0.4588 | MEAN REWARD : -0.38\n",
      "GAME : 1810 | EPSILON : 0.4573 | MEAN REWARD : -0.44\n",
      "GAME : 1815 | EPSILON : 0.4558 | MEAN REWARD : -0.42\n",
      "GAME : 1820 | EPSILON : 0.4543 | MEAN REWARD : -0.36\n",
      "GAME : 1825 | EPSILON : 0.4528 | MEAN REWARD : -0.36\n",
      "GAME : 1830 | EPSILON : 0.4513 | MEAN REWARD : -0.36\n",
      "GAME : 1835 | EPSILON : 0.4498 | MEAN REWARD : -0.34\n",
      "GAME : 1840 | EPSILON : 0.4483 | MEAN REWARD : -0.38\n",
      "GAME : 1845 | EPSILON : 0.4468 | MEAN REWARD : -0.34\n",
      "GAME : 1850 | EPSILON : 0.4453 | MEAN REWARD : -0.32\n",
      "GAME : 1855 | EPSILON : 0.4438 | MEAN REWARD : -0.3\n",
      "GAME : 1860 | EPSILON : 0.4423 | MEAN REWARD : -0.3\n",
      "GAME : 1865 | EPSILON : 0.4408 | MEAN REWARD : -0.28\n",
      "GAME : 1870 | EPSILON : 0.4393 | MEAN REWARD : -0.3\n",
      "GAME : 1875 | EPSILON : 0.4378 | MEAN REWARD : -0.32\n",
      "GAME : 1880 | EPSILON : 0.4363 | MEAN REWARD : -0.28\n",
      "GAME : 1885 | EPSILON : 0.4348 | MEAN REWARD : -0.3\n",
      "GAME : 1890 | EPSILON : 0.4333 | MEAN REWARD : -0.34\n",
      "GAME : 1895 | EPSILON : 0.4318 | MEAN REWARD : -0.32\n",
      "GAME : 1900 | EPSILON : 0.4303 | MEAN REWARD : -0.32\n",
      "GAME : 1905 | EPSILON : 0.4288 | MEAN REWARD : -0.3\n",
      "GAME : 1910 | EPSILON : 0.4273 | MEAN REWARD : -0.28\n",
      "GAME : 1915 | EPSILON : 0.4258 | MEAN REWARD : -0.28\n",
      "GAME : 1920 | EPSILON : 0.4243 | MEAN REWARD : -0.3\n",
      "GAME : 1925 | EPSILON : 0.4228 | MEAN REWARD : -0.28\n",
      "GAME : 1930 | EPSILON : 0.4213 | MEAN REWARD : -0.26\n",
      "GAME : 1935 | EPSILON : 0.4198 | MEAN REWARD : -0.28\n",
      "GAME : 1940 | EPSILON : 0.4183 | MEAN REWARD : -0.26\n",
      "GAME : 1945 | EPSILON : 0.4168 | MEAN REWARD : -0.26\n",
      "GAME : 1950 | EPSILON : 0.4153 | MEAN REWARD : -0.28\n",
      "GAME : 1955 | EPSILON : 0.4138 | MEAN REWARD : -0.26\n",
      "GAME : 1960 | EPSILON : 0.4123 | MEAN REWARD : -0.3\n",
      "GAME : 1965 | EPSILON : 0.4108 | MEAN REWARD : -0.32\n",
      "GAME : 1970 | EPSILON : 0.4093 | MEAN REWARD : -0.28\n",
      "GAME : 1975 | EPSILON : 0.4078 | MEAN REWARD : -0.22\n",
      "GAME : 1980 | EPSILON : 0.4063 | MEAN REWARD : -0.26\n",
      "GAME : 1985 | EPSILON : 0.4048 | MEAN REWARD : -0.26\n",
      "GAME : 1990 | EPSILON : 0.4033 | MEAN REWARD : -0.24\n",
      "GAME : 1995 | EPSILON : 0.4018 | MEAN REWARD : -0.24\n",
      "GAME : 2000 | EPSILON : 0.4003 | MEAN REWARD : -0.22\n",
      "GAME : 2005 | EPSILON : 0.3988 | MEAN REWARD : -0.2\n",
      "GAME : 2010 | EPSILON : 0.3973 | MEAN REWARD : -0.16\n",
      "GAME : 2015 | EPSILON : 0.3958 | MEAN REWARD : -0.14\n",
      "GAME : 2020 | EPSILON : 0.3943 | MEAN REWARD : -0.14\n",
      "GAME : 2025 | EPSILON : 0.3928 | MEAN REWARD : -0.12\n",
      "REWARD -0.22 -> -0.12. Model Saved\n",
      "GAME : 2030 | EPSILON : 0.3913 | MEAN REWARD : -0.1\n",
      "GAME : 2035 | EPSILON : 0.3898 | MEAN REWARD : -0.12\n",
      "GAME : 2040 | EPSILON : 0.3883 | MEAN REWARD : -0.14\n",
      "GAME : 2045 | EPSILON : 0.3868 | MEAN REWARD : -0.18\n",
      "GAME : 2050 | EPSILON : 0.3853 | MEAN REWARD : -0.14\n",
      "GAME : 2055 | EPSILON : 0.3838 | MEAN REWARD : -0.16\n",
      "GAME : 2060 | EPSILON : 0.3823 | MEAN REWARD : -0.1\n",
      "GAME : 2065 | EPSILON : 0.3808 | MEAN REWARD : -0.06\n",
      "GAME : 2070 | EPSILON : 0.3793 | MEAN REWARD : -0.08\n",
      "GAME : 2075 | EPSILON : 0.3778 | MEAN REWARD : -0.1\n",
      "GAME : 2080 | EPSILON : 0.3763 | MEAN REWARD : -0.06\n",
      "GAME : 2085 | EPSILON : 0.3748 | MEAN REWARD : -0.04\n",
      "GAME : 2090 | EPSILON : 0.3733 | MEAN REWARD : -0.06\n",
      "GAME : 2095 | EPSILON : 0.3718 | MEAN REWARD : -0.08\n",
      "GAME : 2100 | EPSILON : 0.3703 | MEAN REWARD : -0.08\n",
      "GAME : 2105 | EPSILON : 0.3688 | MEAN REWARD : -0.14\n",
      "GAME : 2110 | EPSILON : 0.3673 | MEAN REWARD : -0.14\n",
      "GAME : 2115 | EPSILON : 0.3658 | MEAN REWARD : -0.14\n",
      "GAME : 2120 | EPSILON : 0.3643 | MEAN REWARD : -0.16\n",
      "GAME : 2125 | EPSILON : 0.3628 | MEAN REWARD : -0.18\n",
      "GAME : 2130 | EPSILON : 0.3613 | MEAN REWARD : -0.18\n",
      "GAME : 2135 | EPSILON : 0.3598 | MEAN REWARD : -0.16\n",
      "GAME : 2140 | EPSILON : 0.3583 | MEAN REWARD : -0.12\n",
      "GAME : 2145 | EPSILON : 0.3568 | MEAN REWARD : -0.1\n",
      "GAME : 2150 | EPSILON : 0.3553 | MEAN REWARD : -0.1\n",
      "GAME : 2155 | EPSILON : 0.3538 | MEAN REWARD : -0.1\n",
      "GAME : 2160 | EPSILON : 0.3523 | MEAN REWARD : -0.16\n",
      "GAME : 2165 | EPSILON : 0.3508 | MEAN REWARD : -0.12\n",
      "GAME : 2170 | EPSILON : 0.3493 | MEAN REWARD : -0.08\n",
      "GAME : 2175 | EPSILON : 0.3478 | MEAN REWARD : -0.06\n",
      "GAME : 2180 | EPSILON : 0.3463 | MEAN REWARD : -0.1\n",
      "GAME : 2185 | EPSILON : 0.3448 | MEAN REWARD : -0.06\n",
      "GAME : 2190 | EPSILON : 0.3433 | MEAN REWARD : 0.0\n",
      "REWARD -0.12 -> 0.0. Model Saved\n",
      "GAME : 2195 | EPSILON : 0.3418 | MEAN REWARD : 0.0\n",
      "GAME : 2200 | EPSILON : 0.3403 | MEAN REWARD : 0.04\n",
      "GAME : 2205 | EPSILON : 0.3388 | MEAN REWARD : 0.06\n",
      "REWARD 0.0 -> 0.1. Model Saved\n",
      "GAME : 2210 | EPSILON : 0.3373 | MEAN REWARD : 0.04\n",
      "GAME : 2215 | EPSILON : 0.3358 | MEAN REWARD : 0.08\n",
      "GAME : 2220 | EPSILON : 0.3343 | MEAN REWARD : 0.06\n",
      "GAME : 2225 | EPSILON : 0.3328 | MEAN REWARD : 0.04\n",
      "GAME : 2230 | EPSILON : 0.3313 | MEAN REWARD : 0.02\n",
      "GAME : 2235 | EPSILON : 0.3298 | MEAN REWARD : 0.08\n",
      "GAME : 2240 | EPSILON : 0.3283 | MEAN REWARD : 0.1\n",
      "GAME : 2245 | EPSILON : 0.3268 | MEAN REWARD : 0.1\n",
      "GAME : 2250 | EPSILON : 0.3253 | MEAN REWARD : 0.12\n",
      "GAME : 2255 | EPSILON : 0.3238 | MEAN REWARD : 0.14\n",
      "GAME : 2260 | EPSILON : 0.3223 | MEAN REWARD : 0.14\n",
      "GAME : 2265 | EPSILON : 0.3208 | MEAN REWARD : 0.16\n",
      "GAME : 2270 | EPSILON : 0.3193 | MEAN REWARD : 0.12\n",
      "GAME : 2275 | EPSILON : 0.3178 | MEAN REWARD : 0.12\n",
      "GAME : 2280 | EPSILON : 0.3163 | MEAN REWARD : 0.18\n",
      "GAME : 2285 | EPSILON : 0.3148 | MEAN REWARD : 0.14\n",
      "GAME : 2290 | EPSILON : 0.3133 | MEAN REWARD : 0.1\n",
      "GAME : 2295 | EPSILON : 0.3118 | MEAN REWARD : 0.08\n",
      "GAME : 2300 | EPSILON : 0.3103 | MEAN REWARD : 0.1\n",
      "GAME : 2305 | EPSILON : 0.3088 | MEAN REWARD : 0.08\n",
      "GAME : 2310 | EPSILON : 0.3073 | MEAN REWARD : 0.1\n",
      "GAME : 2315 | EPSILON : 0.3058 | MEAN REWARD : 0.06\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GAME : 2320 | EPSILON : 0.3043 | MEAN REWARD : 0.08\n",
      "GAME : 2325 | EPSILON : 0.3028 | MEAN REWARD : 0.1\n",
      "GAME : 2330 | EPSILON : 0.3013 | MEAN REWARD : 0.12\n",
      "GAME : 2335 | EPSILON : 0.2998 | MEAN REWARD : 0.06\n",
      "GAME : 2340 | EPSILON : 0.2983 | MEAN REWARD : 0.02\n",
      "GAME : 2345 | EPSILON : 0.2968 | MEAN REWARD : 0.02\n",
      "GAME : 2350 | EPSILON : 0.2953 | MEAN REWARD : 0.0\n",
      "GAME : 2355 | EPSILON : 0.2938 | MEAN REWARD : -0.06\n",
      "GAME : 2360 | EPSILON : 0.2923 | MEAN REWARD : -0.02\n",
      "GAME : 2365 | EPSILON : 0.2908 | MEAN REWARD : -0.06\n",
      "GAME : 2370 | EPSILON : 0.2893 | MEAN REWARD : -0.04\n",
      "GAME : 2375 | EPSILON : 0.2878 | MEAN REWARD : -0.06\n",
      "GAME : 2380 | EPSILON : 0.2863 | MEAN REWARD : -0.1\n",
      "GAME : 2385 | EPSILON : 0.2848 | MEAN REWARD : -0.12\n",
      "GAME : 2390 | EPSILON : 0.2833 | MEAN REWARD : -0.1\n",
      "GAME : 2395 | EPSILON : 0.2818 | MEAN REWARD : -0.06\n",
      "GAME : 2400 | EPSILON : 0.2803 | MEAN REWARD : -0.1\n",
      "GAME : 2405 | EPSILON : 0.2788 | MEAN REWARD : -0.04\n",
      "GAME : 2410 | EPSILON : 0.2773 | MEAN REWARD : -0.06\n",
      "GAME : 2415 | EPSILON : 0.2758 | MEAN REWARD : -0.04\n",
      "GAME : 2420 | EPSILON : 0.2743 | MEAN REWARD : 0.0\n",
      "GAME : 2425 | EPSILON : 0.2728 | MEAN REWARD : 0.02\n",
      "GAME : 2430 | EPSILON : 0.2713 | MEAN REWARD : 0.0\n",
      "GAME : 2435 | EPSILON : 0.2698 | MEAN REWARD : 0.04\n",
      "GAME : 2440 | EPSILON : 0.2683 | MEAN REWARD : 0.04\n",
      "GAME : 2445 | EPSILON : 0.2668 | MEAN REWARD : 0.08\n",
      "GAME : 2450 | EPSILON : 0.2653 | MEAN REWARD : 0.06\n",
      "GAME : 2455 | EPSILON : 0.2638 | MEAN REWARD : 0.1\n",
      "GAME : 2460 | EPSILON : 0.2623 | MEAN REWARD : 0.08\n",
      "GAME : 2465 | EPSILON : 0.2608 | MEAN REWARD : 0.06\n",
      "GAME : 2470 | EPSILON : 0.2593 | MEAN REWARD : 0.1\n",
      "GAME : 2475 | EPSILON : 0.2578 | MEAN REWARD : 0.08\n",
      "GAME : 2480 | EPSILON : 0.2563 | MEAN REWARD : 0.1\n",
      "GAME : 2485 | EPSILON : 0.2548 | MEAN REWARD : 0.16\n",
      "GAME : 2490 | EPSILON : 0.2533 | MEAN REWARD : 0.18\n",
      "GAME : 2495 | EPSILON : 0.2518 | MEAN REWARD : 0.16\n",
      "GAME : 2500 | EPSILON : 0.2503 | MEAN REWARD : 0.16\n",
      "GAME : 2505 | EPSILON : 0.2488 | MEAN REWARD : 0.14\n",
      "GAME : 2510 | EPSILON : 0.2473 | MEAN REWARD : 0.16\n",
      "GAME : 2515 | EPSILON : 0.2458 | MEAN REWARD : 0.14\n",
      "GAME : 2520 | EPSILON : 0.2443 | MEAN REWARD : 0.14\n",
      "GAME : 2525 | EPSILON : 0.2428 | MEAN REWARD : 0.14\n",
      "GAME : 2530 | EPSILON : 0.2413 | MEAN REWARD : 0.16\n",
      "GAME : 2535 | EPSILON : 0.2398 | MEAN REWARD : 0.14\n",
      "GAME : 2540 | EPSILON : 0.2383 | MEAN REWARD : 0.18\n",
      "GAME : 2545 | EPSILON : 0.2368 | MEAN REWARD : 0.18\n",
      "REWARD 0.1 -> 0.2. Model Saved\n",
      "GAME : 2550 | EPSILON : 0.2353 | MEAN REWARD : 0.22\n",
      "GAME : 2555 | EPSILON : 0.2338 | MEAN REWARD : 0.24\n",
      "GAME : 2560 | EPSILON : 0.2323 | MEAN REWARD : 0.26\n",
      "GAME : 2565 | EPSILON : 0.2308 | MEAN REWARD : 0.28\n",
      "GAME : 2570 | EPSILON : 0.2293 | MEAN REWARD : 0.28\n",
      "REWARD 0.2 -> 0.32. Model Saved\n",
      "GAME : 2575 | EPSILON : 0.2278 | MEAN REWARD : 0.32\n",
      "GAME : 2580 | EPSILON : 0.2263 | MEAN REWARD : 0.34\n",
      "GAME : 2585 | EPSILON : 0.2248 | MEAN REWARD : 0.32\n",
      "GAME : 2590 | EPSILON : 0.2233 | MEAN REWARD : 0.28\n",
      "GAME : 2595 | EPSILON : 0.2218 | MEAN REWARD : 0.32\n",
      "GAME : 2600 | EPSILON : 0.2203 | MEAN REWARD : 0.3\n",
      "GAME : 2605 | EPSILON : 0.2188 | MEAN REWARD : 0.3\n",
      "GAME : 2610 | EPSILON : 0.2173 | MEAN REWARD : 0.32\n",
      "GAME : 2615 | EPSILON : 0.2158 | MEAN REWARD : 0.36\n",
      "GAME : 2620 | EPSILON : 0.2143 | MEAN REWARD : 0.34\n",
      "GAME : 2625 | EPSILON : 0.2128 | MEAN REWARD : 0.36\n",
      "GAME : 2630 | EPSILON : 0.2113 | MEAN REWARD : 0.36\n",
      "GAME : 2635 | EPSILON : 0.2098 | MEAN REWARD : 0.4\n",
      "GAME : 2640 | EPSILON : 0.2083 | MEAN REWARD : 0.34\n",
      "GAME : 2645 | EPSILON : 0.2068 | MEAN REWARD : 0.32\n",
      "GAME : 2650 | EPSILON : 0.2053 | MEAN REWARD : 0.3\n",
      "GAME : 2655 | EPSILON : 0.2038 | MEAN REWARD : 0.3\n",
      "GAME : 2660 | EPSILON : 0.2023 | MEAN REWARD : 0.34\n",
      "GAME : 2665 | EPSILON : 0.2008 | MEAN REWARD : 0.36\n",
      "GAME : 2670 | EPSILON : 0.1993 | MEAN REWARD : 0.3\n",
      "GAME : 2675 | EPSILON : 0.1978 | MEAN REWARD : 0.28\n",
      "GAME : 2680 | EPSILON : 0.1963 | MEAN REWARD : 0.26\n",
      "GAME : 2685 | EPSILON : 0.1948 | MEAN REWARD : 0.28\n",
      "GAME : 2690 | EPSILON : 0.1933 | MEAN REWARD : 0.32\n",
      "GAME : 2695 | EPSILON : 0.1918 | MEAN REWARD : 0.28\n",
      "GAME : 2700 | EPSILON : 0.1903 | MEAN REWARD : 0.32\n",
      "GAME : 2705 | EPSILON : 0.1888 | MEAN REWARD : 0.34\n",
      "GAME : 2710 | EPSILON : 0.1873 | MEAN REWARD : 0.3\n",
      "GAME : 2715 | EPSILON : 0.1858 | MEAN REWARD : 0.3\n",
      "GAME : 2720 | EPSILON : 0.1843 | MEAN REWARD : 0.3\n",
      "GAME : 2725 | EPSILON : 0.1828 | MEAN REWARD : 0.3\n",
      "GAME : 2730 | EPSILON : 0.1813 | MEAN REWARD : 0.32\n",
      "GAME : 2735 | EPSILON : 0.1798 | MEAN REWARD : 0.34\n",
      "GAME : 2740 | EPSILON : 0.1783 | MEAN REWARD : 0.4\n",
      "GAME : 2745 | EPSILON : 0.1768 | MEAN REWARD : 0.38\n",
      "GAME : 2750 | EPSILON : 0.1753 | MEAN REWARD : 0.4\n",
      "GAME : 2755 | EPSILON : 0.1738 | MEAN REWARD : 0.42\n",
      "GAME : 2760 | EPSILON : 0.1723 | MEAN REWARD : 0.4\n",
      "GAME : 2765 | EPSILON : 0.1708 | MEAN REWARD : 0.4\n",
      "REWARD 0.32 -> 0.44. Model Saved\n",
      "GAME : 2770 | EPSILON : 0.1693 | MEAN REWARD : 0.46\n",
      "GAME : 2775 | EPSILON : 0.1678 | MEAN REWARD : 0.44\n",
      "GAME : 2780 | EPSILON : 0.1663 | MEAN REWARD : 0.48\n",
      "GAME : 2785 | EPSILON : 0.1648 | MEAN REWARD : 0.44\n",
      "GAME : 2790 | EPSILON : 0.1633 | MEAN REWARD : 0.44\n",
      "GAME : 2795 | EPSILON : 0.1618 | MEAN REWARD : 0.5\n",
      "GAME : 2800 | EPSILON : 0.1603 | MEAN REWARD : 0.5\n",
      "GAME : 2805 | EPSILON : 0.1588 | MEAN REWARD : 0.52\n",
      "GAME : 2810 | EPSILON : 0.1573 | MEAN REWARD : 0.54\n",
      "REWARD 0.44 -> 0.54. Model Saved\n",
      "GAME : 2815 | EPSILON : 0.1558 | MEAN REWARD : 0.52\n",
      "GAME : 2820 | EPSILON : 0.1543 | MEAN REWARD : 0.54\n",
      "GAME : 2825 | EPSILON : 0.1528 | MEAN REWARD : 0.54\n",
      "GAME : 2830 | EPSILON : 0.1513 | MEAN REWARD : 0.52\n",
      "GAME : 2835 | EPSILON : 0.1498 | MEAN REWARD : 0.5\n",
      "GAME : 2840 | EPSILON : 0.1483 | MEAN REWARD : 0.5\n",
      "GAME : 2845 | EPSILON : 0.1468 | MEAN REWARD : 0.52\n",
      "GAME : 2850 | EPSILON : 0.1453 | MEAN REWARD : 0.54\n",
      "GAME : 2855 | EPSILON : 0.1438 | MEAN REWARD : 0.54\n",
      "GAME : 2860 | EPSILON : 0.1423 | MEAN REWARD : 0.54\n",
      "GAME : 2865 | EPSILON : 0.1408 | MEAN REWARD : 0.54\n",
      "GAME : 2870 | EPSILON : 0.1393 | MEAN REWARD : 0.56\n",
      "GAME : 2875 | EPSILON : 0.1378 | MEAN REWARD : 0.58\n",
      "GAME : 2880 | EPSILON : 0.1363 | MEAN REWARD : 0.52\n",
      "GAME : 2885 | EPSILON : 0.1348 | MEAN REWARD : 0.58\n",
      "GAME : 2890 | EPSILON : 0.1333 | MEAN REWARD : 0.58\n",
      "GAME : 2895 | EPSILON : 0.1318 | MEAN REWARD : 0.54\n",
      "GAME : 2900 | EPSILON : 0.1303 | MEAN REWARD : 0.52\n",
      "GAME : 2905 | EPSILON : 0.1288 | MEAN REWARD : 0.48\n",
      "GAME : 2910 | EPSILON : 0.1273 | MEAN REWARD : 0.5\n",
      "GAME : 2915 | EPSILON : 0.1258 | MEAN REWARD : 0.54\n",
      "GAME : 2920 | EPSILON : 0.1243 | MEAN REWARD : 0.54\n",
      "GAME : 2925 | EPSILON : 0.1228 | MEAN REWARD : 0.54\n",
      "GAME : 2930 | EPSILON : 0.1213 | MEAN REWARD : 0.56\n",
      "GAME : 2935 | EPSILON : 0.1198 | MEAN REWARD : 0.54\n",
      "GAME : 2940 | EPSILON : 0.1183 | MEAN REWARD : 0.54\n",
      "GAME : 2945 | EPSILON : 0.1168 | MEAN REWARD : 0.58\n",
      "GAME : 2950 | EPSILON : 0.1153 | MEAN REWARD : 0.58\n",
      "GAME : 2955 | EPSILON : 0.1138 | MEAN REWARD : 0.56\n",
      "GAME : 2960 | EPSILON : 0.1123 | MEAN REWARD : 0.58\n",
      "GAME : 2965 | EPSILON : 0.1108 | MEAN REWARD : 0.6\n",
      "GAME : 2970 | EPSILON : 0.1093 | MEAN REWARD : 0.58\n",
      "GAME : 2975 | EPSILON : 0.1078 | MEAN REWARD : 0.6\n",
      "GAME : 2980 | EPSILON : 0.1063 | MEAN REWARD : 0.62\n",
      "GAME : 2985 | EPSILON : 0.1048 | MEAN REWARD : 0.6\n",
      "GAME : 2990 | EPSILON : 0.1033 | MEAN REWARD : 0.62\n",
      "GAME : 2995 | EPSILON : 0.1018 | MEAN REWARD : 0.62\n",
      "GAME : 3000 | EPSILON : 0.1003 | MEAN REWARD : 0.62\n",
      "REWARD 0.54 -> 0.66. Model Saved\n",
      "GAME : 3005 | EPSILON : 0.0988 | MEAN REWARD : 0.62\n",
      "GAME : 3010 | EPSILON : 0.0973 | MEAN REWARD : 0.64\n",
      "GAME : 3015 | EPSILON : 0.0958 | MEAN REWARD : 0.6\n",
      "GAME : 3020 | EPSILON : 0.0943 | MEAN REWARD : 0.6\n",
      "GAME : 3025 | EPSILON : 0.0928 | MEAN REWARD : 0.62\n",
      "GAME : 3030 | EPSILON : 0.0913 | MEAN REWARD : 0.64\n",
      "GAME : 3035 | EPSILON : 0.0898 | MEAN REWARD : 0.66\n",
      "GAME : 3040 | EPSILON : 0.0883 | MEAN REWARD : 0.68\n",
      "GAME : 3045 | EPSILON : 0.0868 | MEAN REWARD : 0.66\n",
      "GAME : 3050 | EPSILON : 0.0853 | MEAN REWARD : 0.66\n",
      "GAME : 3055 | EPSILON : 0.0838 | MEAN REWARD : 0.64\n",
      "GAME : 3060 | EPSILON : 0.0823 | MEAN REWARD : 0.62\n",
      "GAME : 3065 | EPSILON : 0.0808 | MEAN REWARD : 0.6\n",
      "GAME : 3070 | EPSILON : 0.0793 | MEAN REWARD : 0.62\n",
      "GAME : 3075 | EPSILON : 0.0778 | MEAN REWARD : 0.62\n",
      "GAME : 3080 | EPSILON : 0.0763 | MEAN REWARD : 0.66\n",
      "GAME : 3085 | EPSILON : 0.0748 | MEAN REWARD : 0.68\n",
      "GAME : 3090 | EPSILON : 0.0733 | MEAN REWARD : 0.62\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GAME : 3095 | EPSILON : 0.0718 | MEAN REWARD : 0.64\n",
      "GAME : 3100 | EPSILON : 0.0703 | MEAN REWARD : 0.66\n",
      "GAME : 3105 | EPSILON : 0.0688 | MEAN REWARD : 0.68\n",
      "GAME : 3110 | EPSILON : 0.0673 | MEAN REWARD : 0.66\n",
      "GAME : 3115 | EPSILON : 0.0658 | MEAN REWARD : 0.7\n",
      "GAME : 3120 | EPSILON : 0.0643 | MEAN REWARD : 0.72\n",
      "GAME : 3125 | EPSILON : 0.0628 | MEAN REWARD : 0.72\n",
      "GAME : 3130 | EPSILON : 0.0613 | MEAN REWARD : 0.72\n",
      "GAME : 3135 | EPSILON : 0.0598 | MEAN REWARD : 0.74\n",
      "GAME : 3140 | EPSILON : 0.0583 | MEAN REWARD : 0.74\n",
      "GAME : 3145 | EPSILON : 0.0568 | MEAN REWARD : 0.76\n",
      "GAME : 3150 | EPSILON : 0.0553 | MEAN REWARD : 0.76\n",
      "GAME : 3155 | EPSILON : 0.0538 | MEAN REWARD : 0.76\n",
      "REWARD 0.66 -> 0.78. Model Saved\n",
      "GAME : 3160 | EPSILON : 0.0523 | MEAN REWARD : 0.78\n",
      "GAME : 3165 | EPSILON : 0.0508 | MEAN REWARD : 0.8\n",
      "GAME : 3170 | EPSILON : 0.0493 | MEAN REWARD : 0.78\n",
      "GAME : 3175 | EPSILON : 0.0478 | MEAN REWARD : 0.78\n",
      "GAME : 3180 | EPSILON : 0.0463 | MEAN REWARD : 0.78\n",
      "GAME : 3185 | EPSILON : 0.0448 | MEAN REWARD : 0.78\n",
      "GAME : 3190 | EPSILON : 0.0433 | MEAN REWARD : 0.82\n",
      "GAME : 3195 | EPSILON : 0.0418 | MEAN REWARD : 0.84\n",
      "GAME : 3200 | EPSILON : 0.0403 | MEAN REWARD : 0.86\n",
      "GAME : 3205 | EPSILON : 0.0388 | MEAN REWARD : 0.86\n",
      "GAME : 3210 | EPSILON : 0.0373 | MEAN REWARD : 0.88\n",
      "GAME : 3215 | EPSILON : 0.0358 | MEAN REWARD : 0.86\n",
      "GAME : 3220 | EPSILON : 0.0343 | MEAN REWARD : 0.84\n",
      "GAME : 3225 | EPSILON : 0.0328 | MEAN REWARD : 0.82\n",
      "GAME : 3230 | EPSILON : 0.0313 | MEAN REWARD : 0.82\n",
      "GAME : 3235 | EPSILON : 0.0298 | MEAN REWARD : 0.82\n",
      "GAME : 3240 | EPSILON : 0.0283 | MEAN REWARD : 0.78\n",
      "GAME : 3245 | EPSILON : 0.0268 | MEAN REWARD : 0.78\n",
      "GAME : 3250 | EPSILON : 0.0253 | MEAN REWARD : 0.78\n",
      "GAME : 3255 | EPSILON : 0.0238 | MEAN REWARD : 0.82\n",
      "GAME : 3260 | EPSILON : 0.0223 | MEAN REWARD : 0.82\n",
      "GAME : 3265 | EPSILON : 0.0208 | MEAN REWARD : 0.82\n",
      "GAME : 3270 | EPSILON : 0.0193 | MEAN REWARD : 0.82\n",
      "GAME : 3275 | EPSILON : 0.0178 | MEAN REWARD : 0.84\n",
      "GAME : 3280 | EPSILON : 0.0163 | MEAN REWARD : 0.84\n",
      "GAME : 3285 | EPSILON : 0.0148 | MEAN REWARD : 0.84\n",
      "GAME : 3290 | EPSILON : 0.0133 | MEAN REWARD : 0.86\n",
      "GAME : 3295 | EPSILON : 0.0118 | MEAN REWARD : 0.86\n",
      "GAME : 3300 | EPSILON : 0.0103 | MEAN REWARD : 0.86\n",
      "GAME : 3305 | EPSILON : 0.0088 | MEAN REWARD : 0.88\n",
      "GAME : 3310 | EPSILON : 0.0073 | MEAN REWARD : 0.88\n",
      "REWARD 0.78 -> 0.9. Model Saved\n",
      "GAME : 3315 | EPSILON : 0.0058 | MEAN REWARD : 0.9\n",
      "GAME : 3320 | EPSILON : 0.0043 | MEAN REWARD : 0.92\n",
      "GAME : 3325 | EPSILON : 0.0028 | MEAN REWARD : 0.94\n",
      "GAME : 3330 | EPSILON : 0.0013 | MEAN REWARD : 0.94\n",
      "GAME : 3335 | EPSILON : 0.0010 | MEAN REWARD : 0.94\n",
      "GAME : 3340 | EPSILON : 0.0010 | MEAN REWARD : 0.96\n",
      "GAME : 3345 | EPSILON : 0.0010 | MEAN REWARD : 0.96\n",
      "GAME : 3350 | EPSILON : 0.0010 | MEAN REWARD : 0.96\n",
      "GAME : 3355 | EPSILON : 0.0010 | MEAN REWARD : 0.96\n",
      "GAME : 3360 | EPSILON : 0.0010 | MEAN REWARD : 0.96\n",
      "GAME : 3365 | EPSILON : 0.0010 | MEAN REWARD : 0.96\n",
      "GAME : 3370 | EPSILON : 0.0010 | MEAN REWARD : 0.98\n",
      "GAME : 3375 | EPSILON : 0.0010 | MEAN REWARD : 0.98\n",
      "GAME : 3380 | EPSILON : 0.0010 | MEAN REWARD : 0.98\n",
      "GAME : 3385 | EPSILON : 0.0010 | MEAN REWARD : 0.98\n",
      "GAME : 3390 | EPSILON : 0.0010 | MEAN REWARD : 0.98\n",
      "GAME : 3395 | EPSILON : 0.0010 | MEAN REWARD : 0.98\n",
      "GAME : 3400 | EPSILON : 0.0010 | MEAN REWARD : 0.98\n",
      "GAME : 3405 | EPSILON : 0.0010 | MEAN REWARD : 0.98\n",
      "GAME : 3410 | EPSILON : 0.0010 | MEAN REWARD : 0.98\n",
      "GAME : 3415 | EPSILON : 0.0010 | MEAN REWARD : 0.98\n",
      "GAME : 3420 | EPSILON : 0.0010 | MEAN REWARD : 0.98\n",
      "GAME : 3425 | EPSILON : 0.0010 | MEAN REWARD : 0.98\n",
      "GAME : 3430 | EPSILON : 0.0010 | MEAN REWARD : 0.98\n",
      "GAME : 3435 | EPSILON : 0.0010 | MEAN REWARD : 0.98\n",
      "GAME : 3440 | EPSILON : 0.0010 | MEAN REWARD : 1.0\n",
      "GAME : 3445 | EPSILON : 0.0010 | MEAN REWARD : 1.0\n",
      "GAME : 3450 | EPSILON : 0.0010 | MEAN REWARD : 1.0\n",
      "GAME : 3455 | EPSILON : 0.0010 | MEAN REWARD : 1.0\n",
      "GAME : 3460 | EPSILON : 0.0010 | MEAN REWARD : 0.98\n",
      "GAME : 3465 | EPSILON : 0.0010 | MEAN REWARD : 0.98\n",
      "GAME : 3470 | EPSILON : 0.0010 | MEAN REWARD : 0.98\n",
      "GAME : 3475 | EPSILON : 0.0010 | MEAN REWARD : 0.98\n",
      "GAME : 3480 | EPSILON : 0.0010 | MEAN REWARD : 0.98\n",
      "GAME : 3485 | EPSILON : 0.0010 | MEAN REWARD : 0.98\n",
      "GAME : 3490 | EPSILON : 0.0010 | MEAN REWARD : 0.98\n",
      "GAME : 3495 | EPSILON : 0.0010 | MEAN REWARD : 0.98\n",
      "GAME : 3500 | EPSILON : 0.0010 | MEAN REWARD : 0.98\n",
      "GAME : 3505 | EPSILON : 0.0010 | MEAN REWARD : 0.98\n",
      "GAME : 3510 | EPSILON : 0.0010 | MEAN REWARD : 0.98\n",
      "GAME : 3515 | EPSILON : 0.0010 | MEAN REWARD : 0.98\n",
      "GAME : 3520 | EPSILON : 0.0010 | MEAN REWARD : 0.98\n",
      "GAME : 3525 | EPSILON : 0.0010 | MEAN REWARD : 0.98\n",
      "GAME : 3530 | EPSILON : 0.0010 | MEAN REWARD : 0.98\n",
      "GAME : 3535 | EPSILON : 0.0010 | MEAN REWARD : 0.98\n",
      "GAME : 3540 | EPSILON : 0.0010 | MEAN REWARD : 0.98\n",
      "GAME : 3545 | EPSILON : 0.0010 | MEAN REWARD : 0.98\n",
      "GAME : 3550 | EPSILON : 0.0010 | MEAN REWARD : 0.98\n",
      "GAME : 3555 | EPSILON : 0.0010 | MEAN REWARD : 0.98\n",
      "GAME : 3560 | EPSILON : 0.0010 | MEAN REWARD : 1.0\n",
      "GAME : 3565 | EPSILON : 0.0010 | MEAN REWARD : 1.0\n",
      "GAME : 3570 | EPSILON : 0.0010 | MEAN REWARD : 1.0\n",
      "GAME : 3575 | EPSILON : 0.0010 | MEAN REWARD : 1.0\n",
      "GAME : 3580 | EPSILON : 0.0010 | MEAN REWARD : 1.0\n",
      "GAME : 3585 | EPSILON : 0.0010 | MEAN REWARD : 1.0\n",
      "GAME : 3590 | EPSILON : 0.0010 | MEAN REWARD : 1.0\n",
      "GAME : 3595 | EPSILON : 0.0010 | MEAN REWARD : 0.98\n",
      "GAME : 3600 | EPSILON : 0.0010 | MEAN REWARD : 0.98\n",
      "GAME : 3605 | EPSILON : 0.0010 | MEAN REWARD : 0.98\n",
      "GAME : 3610 | EPSILON : 0.0010 | MEAN REWARD : 0.98\n",
      "GAME : 3615 | EPSILON : 0.0010 | MEAN REWARD : 0.98\n",
      "GAME : 3620 | EPSILON : 0.0010 | MEAN REWARD : 0.98\n",
      "GAME : 3625 | EPSILON : 0.0010 | MEAN REWARD : 0.98\n",
      "GAME : 3630 | EPSILON : 0.0010 | MEAN REWARD : 0.98\n",
      "GAME : 3635 | EPSILON : 0.0010 | MEAN REWARD : 0.98\n",
      "GAME : 3640 | EPSILON : 0.0010 | MEAN REWARD : 0.98\n",
      "GAME : 3645 | EPSILON : 0.0010 | MEAN REWARD : 0.98\n",
      "GAME : 3650 | EPSILON : 0.0010 | MEAN REWARD : 0.98\n",
      "GAME : 3655 | EPSILON : 0.0010 | MEAN REWARD : 0.98\n",
      "GAME : 3660 | EPSILON : 0.0010 | MEAN REWARD : 0.98\n",
      "GAME : 3665 | EPSILON : 0.0010 | MEAN REWARD : 0.98\n",
      "GAME : 3670 | EPSILON : 0.0010 | MEAN REWARD : 0.98\n",
      "GAME : 3675 | EPSILON : 0.0010 | MEAN REWARD : 0.98\n",
      "GAME : 3680 | EPSILON : 0.0010 | MEAN REWARD : 0.98\n",
      "GAME : 3685 | EPSILON : 0.0010 | MEAN REWARD : 0.98\n",
      "GAME : 3690 | EPSILON : 0.0010 | MEAN REWARD : 0.96\n",
      "GAME : 3695 | EPSILON : 0.0010 | MEAN REWARD : 0.96\n",
      "GAME : 3700 | EPSILON : 0.0010 | MEAN REWARD : 0.96\n",
      "GAME : 3705 | EPSILON : 0.0010 | MEAN REWARD : 0.96\n",
      "GAME : 3710 | EPSILON : 0.0010 | MEAN REWARD : 0.96\n",
      "GAME : 3715 | EPSILON : 0.0010 | MEAN REWARD : 0.96\n",
      "GAME : 3720 | EPSILON : 0.0010 | MEAN REWARD : 0.94\n",
      "GAME : 3725 | EPSILON : 0.0010 | MEAN REWARD : 0.94\n",
      "GAME : 3730 | EPSILON : 0.0010 | MEAN REWARD : 0.94\n",
      "GAME : 3735 | EPSILON : 0.0010 | MEAN REWARD : 0.94\n",
      "GAME : 3740 | EPSILON : 0.0010 | MEAN REWARD : 0.94\n",
      "GAME : 3745 | EPSILON : 0.0010 | MEAN REWARD : 0.94\n",
      "GAME : 3750 | EPSILON : 0.0010 | MEAN REWARD : 0.94\n",
      "GAME : 3755 | EPSILON : 0.0010 | MEAN REWARD : 0.94\n",
      "GAME : 3760 | EPSILON : 0.0010 | MEAN REWARD : 0.94\n",
      "GAME : 3765 | EPSILON : 0.0010 | MEAN REWARD : 0.94\n",
      "GAME : 3770 | EPSILON : 0.0010 | MEAN REWARD : 0.94\n",
      "GAME : 3775 | EPSILON : 0.0010 | MEAN REWARD : 0.94\n",
      "GAME : 3780 | EPSILON : 0.0010 | MEAN REWARD : 0.94\n",
      "GAME : 3785 | EPSILON : 0.0010 | MEAN REWARD : 0.94\n",
      "GAME : 3790 | EPSILON : 0.0010 | MEAN REWARD : 0.96\n",
      "GAME : 3795 | EPSILON : 0.0010 | MEAN REWARD : 0.98\n",
      "GAME : 3800 | EPSILON : 0.0010 | MEAN REWARD : 0.98\n",
      "GAME : 3805 | EPSILON : 0.0010 | MEAN REWARD : 0.98\n",
      "GAME : 3810 | EPSILON : 0.0010 | MEAN REWARD : 0.98\n",
      "GAME : 3815 | EPSILON : 0.0010 | MEAN REWARD : 0.98\n",
      "GAME : 3820 | EPSILON : 0.0010 | MEAN REWARD : 1.0\n",
      "GAME : 3825 | EPSILON : 0.0010 | MEAN REWARD : 1.0\n",
      "GAME : 3830 | EPSILON : 0.0010 | MEAN REWARD : 1.0\n",
      "GAME : 3835 | EPSILON : 0.0010 | MEAN REWARD : 1.0\n",
      "GAME : 3840 | EPSILON : 0.0010 | MEAN REWARD : 1.0\n",
      "GAME : 3845 | EPSILON : 0.0010 | MEAN REWARD : 1.0\n",
      "GAME : 3850 | EPSILON : 0.0010 | MEAN REWARD : 1.0\n"
     ]
    }
   ],
   "source": [
    "all_losses = []\n",
    "device = torch.device( \"cuda\" if torch.cuda.is_available() else \"cpu\" )\n",
    "\n",
    "#Double Dueling DQN\n",
    "net = DDQN( (STATE_DIM,84,84), len(ACTIONS) ).to(device)\n",
    "tgt_net = DDQN( (STATE_DIM,84,84), len(ACTIONS) ).to(device)\n",
    "\n",
    "env = game.GameState()\n",
    "buffer = ExperienceBuffer(EXPERIENCE_BUFFER_SIZE)\n",
    "agent = Agent(env,buffer)\n",
    "epsilon = EPSILON_START\n",
    "optimizer = optim.Adam(net.parameters(),lr=LEARNING_RATE)\n",
    "\n",
    "total_rewards = []\n",
    "best_mean_reward = float('-inf')\n",
    "last_mean = float('-inf')\n",
    "game_id = 0\n",
    "while True:\n",
    "    epsilon = max( EPSILON_FINAL , EPSILON_START - game_id/EPSILON_DECAY_FRAMES )\n",
    "    \n",
    "    reward = agent.step(net,tgt_net,epsilon,device=device)\n",
    "    if reward != 0:\n",
    "        game_id += 1\n",
    "        total_rewards.append(reward)\n",
    "        mean_reward = np.mean(total_rewards[-100:])\n",
    "        if game_id%5 == 0:\n",
    "            print(\"GAME : {} | EPSILON : {:.4f} | MEAN REWARD : {}\".format( game_id, epsilon, mean_reward ))\n",
    "        if best_mean_reward < mean_reward:\n",
    "            best_mean_reward = mean_reward\n",
    "            \n",
    "            if best_mean_reward - last_mean >= 0.1:\n",
    "                torch.save(net.state_dict(),'checkpoints/flappy_best_model.dat')\n",
    "                print(\"REWARD {} -> {}. Model Saved\".format(last_mean,mean_reward))\n",
    "                last_mean = best_mean_reward\n",
    "\n",
    "        if game_id % SYNC_TARGET_FRAMES == 0:\n",
    "            tgt_net.load_state_dict(net.state_dict())\n",
    "            \n",
    "        if mean_reward >= MEAN_GOAL_REWARD:\n",
    "            print(\"Learned in {} Games.\".format(game_id))\n",
    "            break\n",
    "    \n",
    "    if len(buffer) < MIN_EXP_BUFFER_SIZE:\n",
    "        continue\n",
    "    \n",
    "    optimizer.zero_grad()\n",
    "    batch = buffer.sample(BATCH_SIZE)\n",
    "    loss_t = calc_loss(batch,net,tgt_net,device=device)\n",
    "    all_losses.append(float(loss_t))\n",
    "    loss_t.backward()\n",
    "    optimizer.step()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
